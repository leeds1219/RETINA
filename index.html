<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Breaking the Visual Shortcuts in Multimodal Knowledge-Based Visual Question Answering">
  <meta name="keywords" content="keyword placeholder">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Breaking the Visual Shortcuts in Multimodal Knowledge-Based Visual Question Answering</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png"> 

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script>
  <!-- KaTex -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.css">
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/katex.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.4/contrib/auto-render.min.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
        delimiters: [
          {left: "$$", right: "$$", display: true},
          {left: "$", right: "$", display: false}
        ]
      });
    });
  </script>
  <!-- KaTex -->
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Breaking the Visual Shortcuts in Multimodal Knowledge-Based Visual Question Answering</h1>
          <div class="is-size-3 publication-authors">
            <img src="./static/images/ArXiv_logo.png" alt="Logo" style="height: 40px; vertical-align: middle;">
            <b>Preprint</b>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://leeds1219.github.io/">Dosung Lee</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://successful-humor-4db.notion.site/Sangwon-Jung-70109a49767a470092a6ee0d02c78313">Sangwon Jung</a><sup>1,2</sup>,</span>
            <span class="author-block"><a href="https://bykimby.github.io/">Boyoung Kim</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://eurominyoung186.github.io/">Minyoung Kim</a><sup>1</sup>,</span><br>
            <span class="author-block"><a href="https://sung-yeon-kim.github.io/">Sungyeon Kim</a><sup>3</sup>,</span>
            <span class="author-block"><a href="https://www.linkedin.com/in/joonyeongs/">Junyoung Sung</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://phseo.github.io/">Paul Hongsuck Seo</a><sup>1</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Korea University,</span>
            <span class="author-block"><sup>2</sup>KAIST,</span>
            <!--<span class="author-block"><sup>3</sup>Amazon</span>-->
            <br>
          </div>
          <div style="display: flex; justify-content: center; align-items: center;">
            <a href="https://www.korea.edu/sites/en/index.do" target="_blank">
              <img src="./static/images/korea_university.png" alt="korea" style="height: 36px;">&nbsp;&nbsp;&nbsp;
            </a>
            <a href="https://miil.korea.ac.kr/" target="_blank">
              <img src="./static/images/MIIL_full_logo.svg" alt="miil" style="height: 36px;">&nbsp;&nbsp;&nbsp;
            </a>
            <a href="https://www.kaist.ac.kr/en/" target="_blank">
              <img src="./static/images/kaist_logo.png" alt="miil" style="height: 36px;">&nbsp;&nbsp;&nbsp;
            </a>
            <!--<a href="https://www.amazon.com/" target="_blank">
              <img src="./static/images/Amazon_logo.png" alt="miil" style="height: 36px;">&nbsp;&nbsp;&nbsp;
            </a>-->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/doi placeholder"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/doi placeholder"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/leeds1219/RETINA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <img src="./static/images/fig_01.png" class="center"/>
        <div class="content has-text-justified">
          <p>
            Existing Multimodal Knowledge-Based Visual Question Answering (MKB-VQA) benchmarks suffer from “visual shortcuts”, as the query image typically matches the primary subject entity of the target document. We demonstrate that models can exploit these shortcuts, achieving comparable results using visual cues alone. To address this, we introduce Relational Entity Text-Image kNowledge Augmented (RETINA) benchmark, automatically constructed using an LLM-driven pipeline, consisting of a training and human-curated test set. RETINA contains queries referencing secondary subjects (i.e. related entities) and pairs them with images of these related entities, removing the visual shortcut. When evaluated on RETINA existing models show significantly degraded performance, confirming their reliance on the shortcut. Furthermore, we propose Multi-Image MultImodal Retriever (MIMIR), which enriches document embeddings by augmenting images of multiple related entities, effectively handling RETINA, unlike prior work that uses only a single image per document. Our experiments validate the limitations of existing benchmarks and demonstrate the effectiveness of RETINA and MIMIR.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- RETINA -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">RETINA Benchmark</h2>
        <img src="./static/images/fig_02.png" class="center"/>
        <div class="content has-text-justified">
          <p>
            <b>RETINA Benchmark Generation Pipeline</b>
            (a) constructs one-hop neighborhood graphs by extracting named entities (gray
box) related to the answer entity (white box) and their relations using an LLM; (b) samples an query entity (green) and qualifying entity
(teal) to form a target subgraph with the answer entity (red); and (c) feeds the target subgraph into an LLM to generate a textual query and
collect a corresponding image from M2KR Images. The query is then paraphrased to minimize lexical overlap with the document.
          </p>
        </div>
      </div>
    </div>
    <!-- Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Qualitative Generated Examples</h2>
        <img src="./static/images/fig_04.png" class="center"/>
        <div class="content has-text-justified">
          <p>
            <b>Qualitative Examples</b> 
            Existing MKB-VQA benchmarks are biased toward scenarios where the main entity of the target document typically has the same entity as the query image.
To address this bias, we focus on collecting samples that do not permit such visual shortcuts, by deliberately selecting a query image that differ from the main entity of the target Wikipedia document.
          </p>
        </div>
      </div>
    </div>
    <!-- MIMIR -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">MIMIR</h2>
        <div style="text-align: center;">
          <img src="./static/images/fig_03.png" class="center"/>
        </div>
        <div class="content has-text-justified">
          <p>
            <b>Overview of MIMIR Document Encoder Architecture.</b>
            (a) given a document, related named entities are identified with an
LLM, and corresponding images are collected from the KB; (b) textual, global image, and patch-level features are extracted, with patch
features attending to textual features through cross-attention to yield multimodal features; and (c) entity token embeddings are incorporated
into the textual features prior to cross-attention for richer contextualization; (d) the final document embedding jointly integrates textual,
global, and multimodal features projected into the same embedding space.
          </p>
        </div>
      </div>
    </div>
    <!-- Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Qualitative Retrieved Examples</h2>
        <img src="./static/images/fig_05.png" class="center"/>
        <div class="content has-text-justified">
          <p>
            <b>Qualitative Comparison of Retrieval on the RETINA Benchmark. </b>
             Results for (a) single image baseline (MuKA) and (b) MIMIR. GT documents are shown in green, and the query entity within them is also highlighted in green. 
            The single image baseline tends to rely on visual shortcuts, often retrieving documents with images that merely resemble the query. 
            In contrast, MIMIR benefits from additional visual-similarity scoring based on multiple related image-augmented document embeddings, enabling it to correctly retrieve the GT document. 
            These visual results illustrate that both textual and visual information must be jointly considered to solve the task.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{lee2025breaking,
  title={Breaking the Visual Shortcuts in Multimodal Knowledge-Based Visual Question Answering},
  author={Lee, Dosung and Jung, Sangwon and Seo, Paul Hongsuck},
  year={2025},
  journal={Preprint}
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
